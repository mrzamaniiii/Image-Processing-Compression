{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global image_dictionary\n",
    "image_dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global blure_image_dict\n",
    "blur_image_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fft2 , ifft2\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy.fft as fp\n",
    "\n",
    "import scipy.misc\n",
    "\n",
    "from numpy import sqrt\n",
    "\n",
    "from skimage.restoration import denoise_nl_means, estimate_sigma\n",
    "from skimage import data , feature,restoration\n",
    "from skimage import exposure\n",
    "from skimage.exposure import match_histograms\n",
    "from skimage.feature import canny,blob_log\n",
    "\n",
    "from skimage.filters import sobel, threshold_otsu\n",
    "from scipy.signal import butter as butterworth\n",
    "from homofilt import HomomorphicFilter\n",
    "from scipy import ndimage,misc\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "from skimage.metrics import mean_squared_error as mse\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_xy(img):\n",
    "    # img = img.astype(int)\n",
    "    if img.ndim >2:\n",
    "        # print(img)\n",
    "        img = np.float32(img)\n",
    "        img = cv2.cvtColor(np.array(img),cv2.COLOR_RGB2GRAY)\n",
    "        # print(img)\n",
    "    y, bin_edges = np.histogram(img.flatten(), bins=256, range=(0, 256))\n",
    "    return bin_edges[0:-1],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_cliked_button(img,title):\n",
    "    # try:\n",
    "        # a = {}\n",
    "        \n",
    "        img = Image.open(io.BytesIO(list(img.values())[-1]['content']))\n",
    "        img = np.array(img)\n",
    "        # img = cv2.imread(io.BytesIO(list(img.values())[-1]['content']))\n",
    "        image_dictionary.update({title:img})\n",
    "        # print(image_dictionary)\n",
    "        plt.imshow(img)\n",
    "        # print(np.array(img))\n",
    "    # except:\n",
    "        # print(\"No File Uploaded\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c51595a85384a51b9c2bb22b1f00981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FileUpload(value={}, description='Upload'), Textarea(value='', description='title'), But…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact_manual(on_cliked_button,img=widgets.FileUpload(),title=widgets.Textarea());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homomorphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homomorphic_filter(img,a=1,b=1,f=30,n=2):\n",
    "    \"\"\"\n",
    "    filter_params: Parameters to be used on filters:\n",
    "                butterworth:\n",
    "                    f: Cutoff frequency \n",
    "                    n: Order of filter\n",
    "    \"\"\"\n",
    "    homo_filter = HomomorphicFilter(a = a, b = b)\n",
    "    homo_img = np.zeros_like(img)\n",
    "    if img.ndim < 3:\n",
    "        homo_img[:,:] = homo_filter.filter(I=img[:,:], filter_params=[f,n])\n",
    "    else:\n",
    "        for i in range(img.ndim):\n",
    "            homo_img[:,:,i] = homo_filter.filter(I=img[:,:,i], filter_params=[f,n])\n",
    "    return homo_img.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homomorphic_show(img,g_low,g_high,fc):\n",
    "    title = img\n",
    "    img = image_dictionary[img]\n",
    "    homo = homomorphic_filter(img,g_low,g_high,fc)\n",
    "    # print(type(homo))\n",
    "    if img.ndim < 3:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,6))\n",
    "        ax1.imshow(homo,cmap='gray')\n",
    "        ax1.set_title(f'filtered image {title}')\n",
    "        \n",
    "        x,y = histogram_xy(homo)\n",
    "        # print(f'{x},{y}')\n",
    "        ax2.bar(x,y)\n",
    "        ax2.set_title(f'filtered histogram image {title}')\n",
    "        ssim1 = ssim(img,homo)\n",
    "    else:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,6))\n",
    "        ax1.imshow(homo)\n",
    "        ax1.set_title(f'filtered image {title}')\n",
    "        \n",
    "        x,y = histogram_xy(homo)\n",
    "        ax2.bar(x,y)\n",
    "        # print(f'{x},{y}')\n",
    "        ax2.set_title(f'filtered histogram image {title}')\n",
    "        # plt.imshow(homomorphic_filter(img,g_low,g_high,fc))\n",
    "        ssim1 = ssim(img,homo,channel_axis=2)\n",
    "    \n",
    "    \n",
    "    snr = mse(img,homo)\n",
    "    \n",
    "    \n",
    "    print('**********************        SNR is {:.2f}   ,   ssim is {:.2f}        **********************'.format(snr,ssim1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cabc61fb4bea4065a04e6fca9cf0efdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='img: ', options=('a1', 'a2', 'low_contrast', 'x3', 'x4', 'x5')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.homomorphic_show(img, g_low, g_high, fc)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tuple = [(k, v) for k, v in image_dictionary.items()]\n",
    "widgets.interact(homomorphic_show,img=widgets.RadioButtons(\n",
    "    description='img: ',\n",
    "    options=list(image_dictionary.keys())\n",
    "),g_low=widgets.FloatSlider(\n",
    "    value=1,\n",
    "    min=.01,\n",
    "    max=5.0,\n",
    "    step=0.01,\n",
    "    description='g_low:'),g_high=widgets.FloatSlider(\n",
    "    value=1,\n",
    "    min=.01,\n",
    "    max=5.0,\n",
    "    step=0.01,\n",
    "    description='g_high:'),fc=widgets.FloatSlider(\n",
    "    value=30,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='fc:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram equalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalizer(img):\n",
    "    img2 = img.copy()\n",
    "    for i in range(3):\n",
    "        hist,bins = np.histogram(img[...,i].flatten(),256,[0,256])\n",
    "        cdf = hist.cumsum()\n",
    "        cdf_m = np.ma.masked_equal(cdf,0)\n",
    "        cdf_m = (cdf_m - cdf_m.min())*255/(cdf_m.max()-cdf_m.min())\n",
    "\n",
    "        cdf = np.ma.filled(cdf_m,0).astype('uint8')\n",
    "        img2[...,i] = cdf[img[...,i]]\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(img):\n",
    "    title = img\n",
    "    img = image_dictionary[img]\n",
    "    img_hist_x,img_hist_y = histogram_xy(img)\n",
    "    \n",
    "    img_eq = histogram_equalizer(img)\n",
    "    img_eq_hist_x,img_eq_hist_y = histogram_xy(img_eq)\n",
    "    \n",
    "    fig, axs = plt.subplots(2, 2, figsize = (20,10))\n",
    "    axs[0, 0].imshow(img)\n",
    "    axs[0, 0].set_title(f'Original image {title}')\n",
    "    axs[0, 1].bar(img_hist_x,img_hist_y)\n",
    "    axs[0, 1].set_title(f'Histogram of {title}')\n",
    "    axs[1, 0].imshow(img_eq)\n",
    "    axs[1, 0].set_title(f'Equalized image {title}')\n",
    "    axs[1, 1].bar(img_eq_hist_x, img_eq_hist_y)\n",
    "    axs[1, 1].set_title(f'Histogram of equalized image {title}')\n",
    "    \n",
    "    snr = mse(img,img_eq)\n",
    "    if img_eq.ndim > 2:\n",
    "        ssim1 = ssim(img,img_eq,channel_axis=2)\n",
    "    else:\n",
    "        ssim1 = ssim(img,img_eq,channel_axis=1)\n",
    "    \n",
    "    print('**********************        SNR is {:.2f}   ,   ssim is {:.2f}        **********************'.format(snr,ssim1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5117a2761e64cdb87a8982915603072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='img: ', options=('a1', 'a2', 'low_contrast', 'x3', 'x4', 'x5')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.equalize(img)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tuple = [(k, v) for k, v in image_dictionary.items()]\n",
    "widgets.interact(equalize,img=widgets.RadioButtons(\n",
    "    description='img: ',\n",
    "    options=list(image_dictionary.keys())\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_match(img,img_match):\n",
    "    title = img\n",
    "    img = image_dictionary[img]\n",
    "    \n",
    "    # print(img.max())\n",
    "    \n",
    "    title_match = img_match\n",
    "    img_match = image_dictionary[img_match]\n",
    "    # print(img_match.max())\n",
    "    \n",
    "    print(img_match.shape)\n",
    "    cmap = \"viridis\"\n",
    "    if img.ndim > img_match.ndim:\n",
    "        img_match = cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB)\n",
    "        # cmap = \"gray\"\n",
    "    elif img.ndim < img_match.ndim:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        cmap = \"gray\"\n",
    "    # else:\n",
    "    #     cmap = \"viridis\"\n",
    "     \n",
    "    img_hist_x,img_hist_y = histogram_xy(img)\n",
    "    img_match_x,img_match_y = histogram_xy(img_match)\n",
    "    \n",
    "    matched = match_histograms(img, img_match)\n",
    "    \n",
    "    matched = matched.astype(int)\n",
    "    \n",
    "    matched_hist_x,matched_hist_y = histogram_xy(matched)\n",
    "    \n",
    "    fig, (ax1,ax2,ax3,ax4) = plt.subplots(1, 4, figsize = (20,5))\n",
    "    ax1.imshow(img,cmap=cmap)\n",
    "    ax1.set_title(f'Original image {title}')\n",
    "    ax2.bar(img_hist_x,img_hist_y)\n",
    "    ax2.set_title(f'Histogram of {title}') \n",
    "    ax3.imshow(img_match,cmap=cmap)\n",
    "    ax3.set_title(f'Original image {title_match} for match')\n",
    "    ax4.bar(img_match_x,img_match_y)\n",
    "    ax4.set_title(f'OHistogram of {title_match} for match')\n",
    "    fig, (ax5,ax6) = plt.subplots(1, 2, figsize = (20,6))\n",
    "    ax5.imshow(matched,cmap=cmap)\n",
    "    ax5.set_title('Matched image')\n",
    "    ax6.bar(matched_hist_x,matched_hist_y)\n",
    "    ax6.set_title('Histogram of Matched image') \n",
    "    \n",
    "    snr = mse(img,matched)\n",
    "    if img.ndim > 2:\n",
    "        ssim1 = ssim(img,matched,channel_axis=2)\n",
    "    else:\n",
    "        ssim1 = ssim(img,matched,channel_axis=1)\n",
    "    # ssim1 = ssim(img,matched,multichannel=True)\n",
    "    \n",
    "    print('**********************        SNR is {:.2f}   ,   ssim is {:.2f}        **********************'.format(snr,ssim1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad412775e8cb441a93ef4c99b0d60589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='img: ', index=2, options=('a1', 'a2', 'low_contrast', 'x3', 'x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.histogram_match(img, img_match)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tuple = [(k, v) for k, v in image_dictionary.items()]\n",
    "widgets.interact(histogram_match,img=widgets.RadioButtons(\n",
    "    description='img: ',\n",
    "    value = 'low_contrast',\n",
    "    options=list(image_dictionary.keys())\n",
    "),img_match=widgets.RadioButtons(\n",
    "    description='match: ',\n",
    "    value = 'x3',\n",
    "    options=list(image_dictionary.keys())\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_filter(img,sigma,low_threshold,high_threshold):\n",
    "    if low_threshold >= high_threshold:\n",
    "        print('! Error : the high_threshold must grater than low_threshold',end='\\r')\n",
    "        return None\n",
    "    else:\n",
    "        print('ok',end='\\r')\n",
    "    # print('masoud')\n",
    "    title = img\n",
    "    img = image_dictionary[img]\n",
    "    \n",
    "    cmap = \"gray\"\n",
    "    if img.ndim > 2:\n",
    "        # img = np.float32(img)\n",
    "        img = cv2.cvtColor(np.array(img),cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    edges = canny(\n",
    "                image=img,\n",
    "                sigma=sigma,\n",
    "                low_threshold=low_threshold,\n",
    "                high_threshold=high_threshold)\n",
    "    \n",
    "    fig ,(ax1,ax2) = plt.subplots(1,2,figsize=(20,10))\n",
    "    ax1.imshow(img,cmap=cmap)\n",
    "    ax1.set_title(f'Original image {title}')\n",
    "    ax2.imshow(edges,cmap=cmap)\n",
    "    ax2.set_title(f'edges detected of {title}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2ee5e2804944be9a0d27a54ac85b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='img: ', index=4, options=('a1', 'a2', 'low_contrast', 'x3', 'x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.canny_filter(img, sigma, low_threshold, high_threshold)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tuple = [(k, v) for k, v in image_dictionary.items()]\n",
    "\n",
    "widgets.interact(canny_filter,\n",
    "                img=widgets.RadioButtons(description='img: ',value = 'x4',options=list(image_dictionary.keys())),\n",
    "                sigma=widgets.FloatSlider(value=1,min=.01,max=10.0,step=0.01,description='sigma:'),\n",
    "                low_threshold=widgets.IntSlider(value=100,min=1,max=256,step=1,description='low_threshold:'),\n",
    "                high_threshold=widgets.IntSlider(value=200,min=0,max=256,step=1,description='high_threshold:'),\n",
    "                \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Marr_Hildreth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def laplace_of_gaussian(gray_img, sigma=1., kappa=0.75, pad=False):\n",
    "    \"\"\"\n",
    "    Applies Laplacian of Gaussians to grayscale image.\n",
    "\n",
    "    :param gray_img: image to apply LoG to\n",
    "    :param sigma:    Gauss sigma of Gaussian applied to image, <= 0. for none\n",
    "    :param kappa:    difference threshold as factor to mean of image values, <= 0 for none\n",
    "    :param pad:      flag to pad output w/ zero border, keeping input image size\n",
    "    \"\"\"\n",
    "    assert len(gray_img.shape) == 2\n",
    "    img = cv2.GaussianBlur(gray_img, (0, 0), sigma) if 0. < sigma else gray_img\n",
    "    img = cv2.Laplacian(img, cv2.CV_64F)\n",
    "    rows, cols = img.shape[:2]\n",
    "    # min/max of 3x3-neighbourhoods\n",
    "    min_map = np.minimum.reduce(list(img[r:rows-2+r, c:cols-2+c]\n",
    "                                     for r in range(3) for c in range(3)))\n",
    "    max_map = np.maximum.reduce(list(img[r:rows-2+r, c:cols-2+c]\n",
    "                                     for r in range(3) for c in range(3)))\n",
    "    # bool matrix for image value positiv (w/out border pixels)\n",
    "    pos_img = 0 < img[1:rows-1, 1:cols-1]\n",
    "    # bool matrix for min < 0 and 0 < image pixel\n",
    "    neg_min = min_map < 0\n",
    "    neg_min[1 - pos_img] = 0\n",
    "    # bool matrix for 0 < max and image pixel < 0\n",
    "    pos_max = 0 < max_map\n",
    "    pos_max[pos_img] = 0\n",
    "    # sign change at pixel?\n",
    "    zero_cross = neg_min + pos_max\n",
    "    # values: max - min, scaled to 0--255; set to 0 for no sign change\n",
    "    value_scale = 255. / max(1., img.max() - img.min())\n",
    "    values = value_scale * (max_map - min_map)\n",
    "    values[1 - zero_cross] = 0.\n",
    "    # optional thresholding\n",
    "    if 0. <= kappa:\n",
    "        thresh = float(np.absolute(img).mean()) * kappa\n",
    "        values[values < thresh] = 0.\n",
    "    log_img = values.astype(np.uint8)\n",
    "    if pad:\n",
    "        log_img = np.pad(log_img, pad_width=1, mode='constant', constant_values=0)\n",
    "    return log_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Marr_Hildreth(img,sigma,kappa):\n",
    "    \n",
    "    title = img\n",
    "    img = image_dictionary[img]\n",
    "    \n",
    "    if img.ndim > 2:\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "    \n",
    "    # apply LoG\n",
    "    log = laplace_of_gaussian(img,sigma=sigma,kappa=kappa)\n",
    "   \n",
    "    fig,(ax1,ax2) = plt.subplots(1,2,figsize = (25,15))\n",
    "\n",
    "    ax1.imshow(img,cmap='gray')\n",
    "    ax1.set_title(f'Original image {title}')\n",
    "    ax2.imshow(log,cmap='gray')\n",
    "    ax2.set_title(f'edges of image {title}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3325fbce88174da980e946b625e62acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='img: ', index=4, options=('a1', 'a2', 'low_contrast', 'x3', 'x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.Marr_Hildreth(img, sigma, kappa)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tuple = [(k, v) for k, v in image_dictionary.items()]\n",
    "\n",
    "widgets.interact(Marr_Hildreth,\n",
    "                img=widgets.RadioButtons(description='img: ',value = 'x4',options=list(image_dictionary.keys())),\n",
    "                sigma=widgets.FloatSlider(value=1,min=.01,max=10.0,step=0.01,description='sigma:'),\n",
    "                kappa=widgets.FloatSlider(value=10,min=.5,max=100,step=.1,description='diff_threshold:'),  \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(img,sz):\n",
    "    title = img\n",
    "    img = image_dictionary[img]\n",
    "    \n",
    "    if img.ndim > 2:\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    result = ndimage.median_filter(img, size=sz)\n",
    "    \n",
    "    img_hist_x,img_hist_y = histogram_xy(img)\n",
    "    hist_x,hist_y = histogram_xy(result)\n",
    "    fig,ax = plt.subplots(2,2,figsize = (25,15))\n",
    "\n",
    "    ax[0,0].imshow(result,cmap='gray')\n",
    "    ax[0,0].set_title(f'filtered image {title}')\n",
    "    ax[0,1].bar(hist_x,hist_y)\n",
    "    ax[0,1].set_title(f'Histogram filtered image {title}')\n",
    "    ax[1,0].imshow(img,cmap='gray')\n",
    "    ax[1,0].set_title(f'Original image {title}')\n",
    "    ax[1,1].bar(img_hist_x,img_hist_y)\n",
    "    ax[1,1].set_title(f'Histogram Original image {title}')\n",
    "    # plt.imshow(result,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df35cb748c9d4cba9f7d3b4c69446736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='img: ', index=4, options=('a1', 'a2', 'low_contrast', 'x3', 'x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.median(img, sz)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tuple = [(k, v) for k, v in image_dictionary.items()]\n",
    "\n",
    "widgets.interact(median,\n",
    "                img=widgets.RadioButtons(description='img: ',value = 'x4',options=list(image_dictionary.keys())),\n",
    "                sz=widgets.IntSlider(value=3,min=1,max=15,step=2,description='size:'), \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# section 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_blur(img,kind,sz):\n",
    "    kernel_size = sz\n",
    "  \n",
    "    # Create the kernel.\n",
    "    kernel_v = np.zeros((kernel_size, kernel_size))\n",
    "    kernel_h = np.copy(kernel_v)\n",
    "\n",
    "    # Fill the middle row with ones.\n",
    "    kernel_v[:, int((kernel_size - 1)/2)] = np.ones(kernel_size)\n",
    "    kernel_h[int((kernel_size - 1)/2), :] = np.ones(kernel_size)\n",
    "\n",
    "    # Normalize.\n",
    "    kernel_v /= kernel_size\n",
    "    kernel_h /= kernel_size\n",
    "    \n",
    "    if kind == 'v':\n",
    "        vertical_mb = cv2.filter2D(img, -1, kernel_v)\n",
    "        return vertical_mb\n",
    "    elif kind == 'h':\n",
    "        horizonal_mb = cv2.filter2D(img, -1, kernel_h)\n",
    "        return horizonal_mb\n",
    "    else:\n",
    "        print(\"the kind of kernel is wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_bluring(img,blur,sz):\n",
    "    title = img\n",
    "    img = image_dictionary[img]\n",
    "\n",
    "    blured_title = f'blured_{title}'\n",
    "    \n",
    "    if blur == 'motion_horizontal':\n",
    "        blured = motion_blur(img,'h',sz)\n",
    "    elif blur == 'motion_vertical':\n",
    "        blured = motion_blur(img,'v',sz)\n",
    "    elif blur == 'out_of_focus':\n",
    "        blured = motion_blur(img,'h',sz)\n",
    "        blured = motion_blur(blured,'v',sz)\n",
    "    else:\n",
    "        print('error')\n",
    "        # return None\n",
    "       \n",
    "    blured_hist_x,blured_hist_y = histogram_xy(blured)\n",
    "    img_his_x,img_his_y = histogram_xy(img)\n",
    "    # blured = motion_blur(img,'h',sz)\n",
    "    \n",
    "    if blured_title in blur_image_dict:\n",
    "        blur_image_dict[blured_title] = blured\n",
    "    else:\n",
    "        blur_image_dict.update({blured_title:blured})\n",
    "    \n",
    "    # print(img)\n",
    "    \n",
    "    cmap = \"viridis\"\n",
    "    if img.ndim < 3 :\n",
    "        cmap = \"gray\"\n",
    "    fig,ax = plt.subplots(2,2,figsize = (25,15))\n",
    "    ax[0,0].imshow(img,cmap=cmap)\n",
    "    ax[0,0].set_title(f'Original image {title}')\n",
    "    ax[0,1].imshow(blured,cmap=cmap)\n",
    "    ax[0,1].set_title(f'blured image {title}')\n",
    "    ax[1,0].bar(img_his_x,img_his_y)\n",
    "    ax[1,0].set_title(f'Histogram of Original image {title}')\n",
    "    ax[1,1].bar(blured_hist_x,blured_hist_y)\n",
    "    ax[1,1].set_title(f'Histogram of blured image {title}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda76003b35c45f9a201bc2a384dc10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='img: ', index=4, options=('a1', 'a2', 'low_contrast', 'x3', 'x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.do_bluring(img, blur, sz)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tuple = [(k, v) for k, v in image_dictionary.items()]\n",
    "\n",
    "widgets.interact(do_bluring,\n",
    "                img=widgets.RadioButtons(description='img: ',value = 'x4',options=list(image_dictionary.keys())),\n",
    "                blur=widgets.RadioButtons(description='blur: ',options=['motion_horizontal','motion_vertical','out_of_focus']),\n",
    "                sz=widgets.IntSlider(value=3,min=1,max=200,step=2,description='size:')\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wiener filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import gaussian, convolve2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener_filter(img, kernel, K):\n",
    "    kernel /= np.sum(kernel)\n",
    "    dummy = np.copy(img)\n",
    "    dummy = fft2(dummy)\n",
    "    kernel = fft2(kernel, s = img.shape)\n",
    "    kernel = np.conj(kernel) / (np.abs(kernel) ** 2 + K)\n",
    "    dummy = dummy * kernel\n",
    "    dummy = np.abs(ifft2(dummy))\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(kernel_size = 3):\n",
    "    h = gaussian(kernel_size, kernel_size / 3).reshape(kernel_size, 1)\n",
    "    h = np.dot(h, h.transpose())\n",
    "    h /= np.sum(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiener(img,sz):\n",
    "    title = img\n",
    "    img = blur_image_dict[title]\n",
    "    img = img.astype(float)\n",
    "    \n",
    "    org_img = title.replace('blured_', '')\n",
    "    org_img = image_dictionary[org_img]\n",
    "    \n",
    "    org_img = org_img.astype(float)\n",
    "    \n",
    "    \n",
    "    \n",
    "    K = 10\n",
    "    kernel = gaussian_kernel(sz)\n",
    "    restored = wiener_filter(img, kernel, K = K)\n",
    "\n",
    "    \n",
    "    \n",
    "#     sigma_est = np.mean(estimate_sigma(img, channel_axis=2))\n",
    "#     restored = denoise_nl_means(img, h=sz * sigma_est, fast_mode=False,\n",
    "#                                 patch_size=5, patch_distance=3, multichannel=False)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # base_image = image_dictionary['x3']\n",
    "    # param = 50\n",
    "#     psf = np.ones((sz, sz)) / 25\n",
    "#     restored,_ = restoration.unsupervised_wiener(img,psf)\n",
    "    \n",
    "    # restored = wiener_filter(img,base_image)\n",
    "    \n",
    "#     from scipy.signal.signaltools import wiener\n",
    "#     restored = wiener(img, (sz, sz))\n",
    "    \n",
    "    fig,(ax1,ax2) = plt.subplots(1,2,figsize=(20,10))\n",
    "    ax1.imshow(restored,cmap='gray')\n",
    "    ax2.imshow(img,cmap='gray')   \n",
    "    # print(img.replace('blured_', ''))\n",
    "    # img = image_dictionary[img]\n",
    "    \n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492694237d064bafbddf0761c5e4c0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='img: ', options=('blured_x4',), value='blured_x4'), IntSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.wiener(img, sz)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widgets.interact(wiener,\n",
    "                img=widgets.RadioButtons(description='img: ',options=list(blur_image_dict.keys())),\n",
    "                sz=widgets.IntSlider(value=3,min=1,max=100,step=2,description='size:')\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroML.filters import savitzky_golay, wiener_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkﬁlter = sitk.WienerDeconvolutionImageFilter()\n",
    "tkﬁlter.SetNoiseVariance(0)\n",
    "tkﬁlter.SetNormalize(True)\n",
    "im_res_WN = sitk.GetArrayFromImage(tkﬁlter.Execute\n",
    "(sitk.GetImageFromArray(im_blur),\n",
    "sitk.GetImageFromArray(psf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
